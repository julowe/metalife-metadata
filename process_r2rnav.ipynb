{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R2R Navigation Data Processor\n",
    "\n",
    "This notebook processes R2R NAV files containing ship navigation data. It can:\n",
    "- Download R2R NAV files from provided URLs\n",
    "- Parse time, latitude, and longitude data\n",
    "- Calculate track lengths in kilometers, miles, and nautical miles\n",
    "- Provide statistics for individual files and totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "from geopy.distance import geodesic\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, output_dir='data'):\n",
    "    \"\"\"Download a file from a URL and save it locally\"\"\"\n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "    filename = os.path.join(output_dir, url.split('/')[-1])\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        print(f\"File {filename} already exists, skipping download\")\n",
    "        return filename\n",
    "    \n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_r2rnav(filepath):\n",
    "    \"\"\"Read an R2R NAV file into a pandas DataFrame with validation\"\"\"\n",
    "    data = []\n",
    "    invalid_lines = []\n",
    "    line_number = 0\n",
    "\n",
    "    def is_valid_datetime(dt_str):\n",
    "        try:\n",
    "            # Check if string follows ISO8601 format and can be parsed\n",
    "            pd.to_datetime(dt_str)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def is_valid_longitude(lon_str):\n",
    "        try:\n",
    "            lon = float(lon_str)\n",
    "            return -180 <= lon <= 180\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def is_valid_latitude(lat_str):\n",
    "        try:\n",
    "            lat = float(lat_str)\n",
    "            return -90 <= lat <= 90\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line_number += 1\n",
    "            if not line.startswith('//') and not line.startswith('#'):\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 3:\n",
    "                    dt, lon, lat = parts[:3]\n",
    "\n",
    "                    # Validate each field\n",
    "                    if not is_valid_datetime(dt):\n",
    "                        invalid_lines.append(f\"Line {line_number}: Invalid datetime format: {dt}\")\n",
    "                        continue\n",
    "                    if not is_valid_longitude(lon):\n",
    "                        invalid_lines.append(f\"Line {line_number}, {dt}: Invalid longitude value: {lon}\")\n",
    "                        continue\n",
    "                    if not is_valid_latitude(lat):\n",
    "                        invalid_lines.append(f\"Line {line_number}, {dt}: : Invalid latitude value: {lat}\")\n",
    "                        continue\n",
    "\n",
    "                    data.append(parts[:3])\n",
    "\n",
    "    # If any invalid lines were found, print warnings\n",
    "    if invalid_lines:\n",
    "        print(f\"\\nWarnings while reading {os.path.basename(filepath)}:\")\n",
    "        for warning in invalid_lines:\n",
    "            print(warning)\n",
    "        print()\n",
    "\n",
    "    if not data:\n",
    "        raise ValueError(f\"No valid data found in {filepath}\")\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data, columns=['datetime', 'longitude', 'latitude'])\n",
    "\n",
    "    # Convert types\n",
    "    # df['datetime'] = pd.to_datetime(df['datetime']).dt.floor('min')\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df['longitude'] = pd.to_numeric(df['longitude'])\n",
    "    df['latitude'] = pd.to_numeric(df['latitude'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_track_length(df):\n",
    "    \"\"\"Calculate the total track length from a DataFrame of coordinates\"\"\"\n",
    "    total_distance_km = 0\n",
    "    \n",
    "    for i in range(len(df) - 1):\n",
    "        point1 = (df.iloc[i]['latitude'], df.iloc[i]['longitude'])\n",
    "        point2 = (df.iloc[i + 1]['latitude'], df.iloc[i + 1]['longitude'])\n",
    "        distance = geodesic(point1, point2).kilometers\n",
    "        total_distance_km += distance\n",
    "    \n",
    "    # Convert to different units\n",
    "    total_distance_mi = total_distance_km * 0.621371\n",
    "    total_distance_nm = total_distance_km * 0.539957\n",
    "    \n",
    "    return {\n",
    "        'kilometers': total_distance_km,\n",
    "        'miles': total_distance_mi,\n",
    "        'nautical_miles': total_distance_nm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: also return start/end times and elapsed time\n",
    "#  nav data *should* usually cover at least the portion of the cruise timeframe from leaving port to returning.\n",
    "#  will have to think about how to trim sitting in port vs sitting on station with rov dive.\n",
    "#  maybe straightforward enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate distance using Haversine formula (great-circle distance).\n",
    "    Assumes spherical Earth.\n",
    "\n",
    "    Returns distance in kilometers.\n",
    "    \"\"\"\n",
    "    EARTH_RADIUS_KM = 6371.0\n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = (\n",
    "        math.sin(dlat / 2) ** 2\n",
    "        + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
    "    )\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    \n",
    "    return EARTH_RADIUS_KM * c\n",
    "\n",
    "def filter_by_min_distance(df, min_distance_m=10.0):\n",
    "    \"\"\"\n",
    "    Keep only points that have moved at least min_distance from previous kept point.\n",
    "    Useful for removing GPS jitter while stationary.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with lat/lon columns\n",
    "        min_distance_m: Minimum distance in meters between consecutive points\n",
    "\n",
    "    Returns:\n",
    "        Filtered DataFrame\n",
    "    \"\"\"\n",
    "    if len(df) <= 1:\n",
    "        return df\n",
    "\n",
    "    kept_indices = [0]  # Always keep first point\n",
    "    last_kept = 0\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        # Provide coordinates in correct order for haversine (lat1, lon1, lat2, lon2)\n",
    "        dist = (\n",
    "            haversine_distance(\n",
    "                df.iloc[last_kept][\"latitude\"],\n",
    "                df.iloc[last_kept][\"longitude\"],\n",
    "                df.iloc[i][\"latitude\"],\n",
    "                df.iloc[i][\"longitude\"],\n",
    "            )\n",
    "            * 1000\n",
    "        )  # Convert to meters\n",
    "\n",
    "        if dist >= min_distance_m:\n",
    "            kept_indices.append(i)\n",
    "            last_kept = i\n",
    "\n",
    "    return df.iloc[kept_indices].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_r2rnav_file(filepath):\n",
    "    \"\"\"Process a single R2R NAV file and return stats and point count\"\"\"\n",
    "    df = read_r2rnav(filepath)\n",
    "    \n",
    "    # Apply minimum distance filter for 1-minute files\n",
    "    # Using 7.5m (approx 0.25 knots) to filter out GPS jitter while stationary\n",
    "    if '1min' in os.path.basename(filepath):\n",
    "        df = filter_by_min_distance(df, min_distance_m=7.5)\n",
    "        \n",
    "    stats = calculate_track_length(df)\n",
    "    \n",
    "    if not df.empty:\n",
    "        start_time = df['datetime'].min()\n",
    "        end_time = df['datetime'].max()\n",
    "        elapsed_hours = (end_time - start_time).total_seconds() / 3600\n",
    "        stats['elapsed_hours'] = round(elapsed_hours, 1)\n",
    "        stats['start_time'] = start_time\n",
    "        stats['end_time'] = end_time\n",
    "        \n",
    "    return stats, len(df)\n",
    "\n",
    "def download_and_process_r2rnav(url, cruise_id, output_dir='data-local'):\n",
    "    \"\"\"Download and process an R2R NAV file\"\"\"\n",
    "    try:\n",
    "        filename = download_file(url, output_dir)\n",
    "        return process_single_r2rnav_file(filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {cruise_id}: {e}\")\n",
    "        return None, 0\n",
    "\n",
    "def read_simple_csv_nav(filepath):\n",
    "    \"\"\"Read a simple CSV nav file (stub)\"\"\"\n",
    "    # TODO: Implement reading of simple CSV format\n",
    "    # Expected format: timestamp, latitude, longitude\n",
    "    try:\n",
    "        # df = pd.read_csv(filepath)\n",
    "        # return df\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV {filepath}: {e}\")\n",
    "\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def process_files(file_paths):\n",
    "    \"\"\"Process multiple R2R NAV files and return statistics\"\"\"\n",
    "    results = []\n",
    "    total_stats = {'kilometers': 0, 'miles': 0, 'nautical_miles': 0}\n",
    "\n",
    "    iterator = tqdm(file_paths, desc=\"Processing files\", unit=\"file\")\n",
    "\n",
    "    for file_path in iterator:\n",
    "        iterator.set_description(f\"Processing {os.path.basename(file_path)}\")\n",
    "\n",
    "        df = read_r2rnav(file_path)\n",
    "        \n",
    "        # Apply minimum distance filter for 1-minute files\n",
    "        # Using 7.5m (approx 0.25 knots) to filter out GPS jitter while stationary\n",
    "        if '1min' in os.path.basename(file_path):\n",
    "            df = filter_by_min_distance(df, min_distance_m=7.5)\n",
    "            \n",
    "        stats = calculate_track_length(df)\n",
    "        \n",
    "        start_time = df['datetime'].min()\n",
    "        end_time = df['datetime'].max()\n",
    "        elapsed_hours = (end_time - start_time).total_seconds() / 3600\n",
    "\n",
    "        results.append({\n",
    "            'file': os.path.basename(file_path),\n",
    "            'start_time': start_time.strftime('%Y-%m-%dT%H:%M'),\n",
    "            'end_time': end_time.strftime('%Y-%m-%dT%H:%M'),\n",
    "            'elapsed_hours': round(elapsed_hours, 1),\n",
    "            'points': len(df),\n",
    "            **stats\n",
    "        })\n",
    "        \n",
    "        # Update totals\n",
    "        for key in total_stats:\n",
    "            total_stats[key] += stats[key]\n",
    "    \n",
    "    return pd.DataFrame(results), total_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Process Local Files\n",
    "\n",
    "You can process local R2R NAV files by providing their paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with local files\n",
    "\n",
    "# use this for local files\n",
    "#local_files = [f for f in os.listdir() if f.endswith('.r2rnav')]\n",
    "\n",
    "# use this for test files\n",
    "#local_files = [os.path.join('tests', f) for f in os.listdir('tests') if f.endswith('.r2rnav')]\n",
    "\n",
    "# NOTE: setting to empty so we don't process any files\n",
    "local_files = []\n",
    "if local_files:\n",
    "    results_df, totals = process_files(local_files)\n",
    "\n",
    "    print(\"\\nResults per file:\")\n",
    "    display(results_df)\n",
    "\n",
    "    print(\"\\nTotal distances:\")\n",
    "    for unit, distance in totals.items():\n",
    "        # Print current time before processing next unit\n",
    "        print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        print(f\"Total distance in {unit}: {distance:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Download and Process Files from URLs\n",
    "\n",
    "You can also download and process files from URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with URLs\n",
    "urls = [\n",
    "    # Add your URLs here\n",
    "    # \"http://example.com/file1.r2rnav\",\n",
    "    # \"http://example.com/file2.r2rnav\"\n",
    "]\n",
    "\n",
    "if urls:\n",
    "    # Download files\n",
    "    downloaded_files = []\n",
    "    for url in tqdm(urls, desc=\"Downloading files\"):\n",
    "        try:\n",
    "            filename = download_file(url)\n",
    "            downloaded_files.append(filename)\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {url}: {e}\")\n",
    "\n",
    "    # Process downloaded files\n",
    "    if downloaded_files:\n",
    "        results_df, totals = process_files(downloaded_files)\n",
    "        \n",
    "        print(\"\\nResults per file:\")\n",
    "        display(results_df)\n",
    "        \n",
    "        print(\"\\nTotal distances:\")\n",
    "        for unit, distance in totals.items():\n",
    "            print(f\"Total distance in {unit}: {distance:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
