{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tell me about my seatime (Using information from R2R)\n",
    "\n",
    "The Rolling Deck to Repository (R2R) Program publishes a [beautiful API here](https://www.rvdata.us/about/technical-details/services/api).\n",
    "\n",
    "The intention is to use a person's name to get all cruises they were on, then days on the ship, then miles sailed on each cruise.\n",
    "\n",
    "## Process Flow\n",
    "\n",
    "To get the cruises a person was on:\n",
    "\n",
    "1. run a `/person/person_id/{person_id}` query for iterations of Last and First names.\n",
    "2. Get a person's list of cruises from NautilusLive.org\n",
    "\n",
    "To get days and miles sailed, get data from R2R then process retrieved data file and/or local data files. Loop through all applicable cruises and process files (in order of preference of formats) :\n",
    "\n",
    "1. Get R2R format processed nav from a `/product/cruise_id/{cruise_id}` query (not all cruises have this data ready to download)\n",
    "2. get INS data from `/fileset/cruise_id/{cruise_id}` query\n",
    "3. get data from OET people and just put it in data-local directory\n",
    "\n",
    "aaaand then process that data. Using... ?\n",
    "\n",
    "## TODOs\n",
    "\n",
    "- [ ] some entries had `file_format` but not `url` or `actual_url`. deal with.\n",
    "  - [x] check if `actual_url` is present, non-empty, and valid.\n",
    "  - [ ] write code for downloading files that have URLs\n",
    "- [ ] lookup geo and/or nav libraries and see if easy option to parse nav files\n",
    "- [ ] how best to look for errors or variations in spelling of someone's name?\n",
    "  - ~~[ ] get all expeditions of a ship (within a timeframe?) and join the names?~~\n",
    "  - [x] display all cruises returned for that person with the cruise's dates and leave it up to them to double-check\n",
    "  - [x] implement the combination of results from multiple searches with name variations\n",
    "  - [ ] allow user to manually add cruise IDs that were not found in R2R or NautilusLive. Explain where to put data files.\n",
    "- [ ] parse [R2R formatted processed nav data](https://service.rvdata.us/info/format/100157)\n",
    "- [ ] parse other r2rnav data type?\n",
    "- [ ] ?parse INS data? or just say 'sorry, wait for the data to be available'?\n"
   ],
   "id": "284fb908a0bc5fc7"
  },
  {
   "cell_type": "code",
   "id": "fb4e9dff",
   "metadata": {},
   "source": [
    "import time\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.auto import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ebf461c7",
   "metadata": {},
   "source": [
    "# Edit the values of these two variables to the person to search for\n",
    "# the variables are lists in order to account for multiple names due to spelling/punctation variations/mistakes, changed first or last names, etc.\n",
    "# e.g. lastNames = [\"Obrien\", \"O'Brien\", \"O'brian\"] etc. - for instances where the metadata sent to r2r was entered incorrectly\n",
    "# Note: Capitalization does not matter at all for r2r, and the names are converted to lowercase for NautilusLive.org\n",
    "# DO NOT use this to search for multiple people at once, it will join their records.\n",
    "lastNames = [\"Lowe\"]\n",
    "firstNames = [\"Justin\"]\n",
    "\n",
    "# How many seconds should we wait between making requests to R2R api?\n",
    "wait_time = 0.5\n",
    "req_timeout = 15"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Get Cruises from R2R with Person's Name(s)",
   "id": "f4958328fa22562"
  },
  {
   "cell_type": "code",
   "id": "67470653",
   "metadata": {},
   "source": [
    "# get cruises from r2r\n",
    "# https://www.rvdata.us/about/technical-details/services/api\n",
    "# Use format `LastName, FirstName` as person_id\n",
    "\n",
    "tempSetCruises = set()\n",
    "\n",
    "# Try all combinations of first and last names\n",
    "for lastName in lastNames:\n",
    "    for firstName in firstNames:\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                \"https://service.rvdata.us/api/person/person_id/{0}%2C%20{1}\".format(\n",
    "                    lastName, firstName\n",
    "                ),\n",
    "                timeout=req_timeout,\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "\n",
    "            searchNameResults = response.json()[\"data\"]\n",
    "\n",
    "            for cruiseResult in searchNameResults:\n",
    "                tempSetCruises.add(cruiseResult[\"cruise_id\"])\n",
    "\n",
    "            print(\n",
    "                \"Found {0} cruises for {1} {2}: {3}\".format(\n",
    "                    len(tempSetCruises), firstName, lastName, \", \".join(sorted(tempSetCruises))\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if len(firstNames) > 1 or len(lastNames) > 1:\n",
    "                # Pause between requests to be nice\n",
    "                time.sleep(wait_time)\n",
    "\n",
    "        except requests.exceptions.HTTPError as errh:\n",
    "            print(f\"HTTP Error for {firstName} {lastName}: {errh}\")\n",
    "        except requests.exceptions.ConnectionError as errc:\n",
    "            print(f\"Connection Error for {firstName} {lastName}: {errc}\")\n",
    "        except requests.exceptions.Timeout as errt:\n",
    "            print(f\"Timeout Error for {firstName} {lastName}: {errt}\")\n",
    "        except requests.exceptions.RequestException as err:\n",
    "            print(f\"Error for {firstName} {lastName}: {err}\")\n",
    "\n",
    "if len(firstNames) > 1 or len(lastNames) > 1:\n",
    "    print(\n",
    "        \"\\nFinal sorted list of all cruises found: {0}\".format(\n",
    "            \", \".join(sorted(tempSetCruises))\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\n",
    "    \"NOTE: If you notice any missing cruises or cruises you weren't on, you can modify the 'lastNames' and 'firstNames' lists at the top of this notebook.\"\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Try to also get Cruises from Person's page on NautilusLive.org",
   "id": "229e4d6f85435e75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Also get cruise IDs from links on the user's NautilusLive.org page (if applicable)\n",
    "nlSetCruises = set()\n",
    "\n",
    "# NautilusLive.org user page base URL\n",
    "nautilusLivePageURL = \"https://nautiluslive.org/people/\"\n",
    "\n",
    "nlCruises = dict()\n",
    "\n",
    "# Try all combinations of names\n",
    "for firstName in firstNames:\n",
    "    for lastName in lastNames:\n",
    "        # combine first name with last name with hyphens, all lowercase\n",
    "        nautilusLivePageName = \"-\".join([firstName, lastName]).lower()\n",
    "\n",
    "        try:\n",
    "            # use BeautifulSoup to parse the HTML page and extract the links from all <div> elements with class=\"cruises\"\n",
    "            response = requests.get(nautilusLivePageURL + nautilusLivePageName)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            # find all <div> elements with class=\"cruises\"\n",
    "            cruiseLinks = soup.find_all(\"div\", class_=\"cruises\")\n",
    "\n",
    "            # extract the href attribute from each <a> element in the <div> elements with class=\"cruises\"\n",
    "            for div in cruiseLinks:\n",
    "                a_tags = div.find_all('a')\n",
    "                for a in a_tags:\n",
    "                    href = a.get('href')\n",
    "                    if href:\n",
    "                        # parse out the cruise ID from the href attribute e.g. \"NA160\" from \"/cruise/NA160\"\n",
    "                        cruise_id = href.split('/')[-1]\n",
    "                        # Validate it is a valid cruise ID of the format \"NA\" and then three numbers\n",
    "                        if cruise_id.startswith('NA') and len(cruise_id) == 5:\n",
    "                            nlSetCruises.add(cruise_id)\n",
    "\n",
    "                            # get name of link from <a> element\n",
    "                            cruise_name = a.get_text()\n",
    "                            # add cruise_id and cruise_name to nlCruises dict\n",
    "                            nlCruises[cruise_id] = cruise_name\n",
    "\n",
    "            if len(firstNames) > 1 or len(lastNames) > 1:\n",
    "                print(\n",
    "                    \"Found the following cruises on NautilusLive.org for {0} {1}\".format(\n",
    "                        firstName, lastName\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            time.sleep(wait_time)  # Be nice to the server\n",
    "\n",
    "        except requests.exceptions.RequestException as err:\n",
    "            print(f\"Error accessing NautilusLive.org for {firstName} {lastName}: {err}\")\n",
    "\n",
    "print(\n",
    "    \"\\nFinal sorted list of cruises from NautilusLive.org has {0} cruises: {1}. \\n\".format(\n",
    "        len(nlSetCruises),\n",
    "        \", \".join(sorted(nlSetCruises))\n",
    "    )\n",
    ")\n",
    "\n",
    "# print out any cruises that are missing from either list\n",
    "if nlCruises and nlSetCruises != tempSetCruises:\n",
    "    missing_from_nl = sorted(tempSetCruises.difference(nlSetCruises))\n",
    "    if missing_from_nl:\n",
    "        if len(missing_from_nl) > 1:\n",
    "            print(\"These {0} R2R cruises are missing from the person's NautilusLive list: {1}\".format(\n",
    "                len(missing_from_nl), \", \".join(missing_from_nl)))\n",
    "        else:\n",
    "            print(\"This {0} R2R cruise is missing from the person's NautilusLive list: {1}\".format(\n",
    "                len(missing_from_nl), missing_from_nl[0]))\n",
    "\n",
    "    missing_from_r2r = sorted(nlSetCruises.difference(tempSetCruises))\n",
    "    if missing_from_r2r:\n",
    "        if len(missing_from_r2r) > 1:\n",
    "            print(\n",
    "                \"These {0} NautilusLive cruises are missing from the person's R2R list: {1}\".format(\n",
    "                    len(missing_from_r2r),\n",
    "                    \", \".join(missing_from_r2r),\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"This {0} NautilusLive cruise is missing from the person's R2R list: {1}\".format(\n",
    "                    len(missing_from_r2r),\n",
    "                    missing_from_r2r[0],\n",
    "                )\n",
    "            )\n",
    "\n",
    "# TODO: use a new variable instead of just adding to existing set?\n",
    "print(\"Cruise list had {0} cruises from R2R\".format(len(tempSetCruises)))\n",
    "tempSetCruises = tempSetCruises.union(nlSetCruises)\n",
    "print(\"Cruise list now has {0} cruises from R2R and NautilusLive\".format(len(tempSetCruises)))\n",
    "#print(\", \".join(sorted(tempSetCruises)))\n",
    "\n",
    "# TODO: ask user if they want to union both sets of cruises? or just keep as is and add them without asking"
   ],
   "id": "86f09e6d5f416e10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Get metadata about each Cruise",
   "id": "1149a2c849236384"
  },
  {
   "cell_type": "code",
   "id": "1f7af198",
   "metadata": {},
   "source": [
    "# Loop through Cruises and get data. Use: dates, `has_r2rnav`, ?\n",
    "\n",
    "# exampleDict =\t{\n",
    "#     cruiseID: {\n",
    "#         \"cruise_id\": TEXT,\n",
    "#         \"cruise_name\": TEXT,\n",
    "#         \"depart_date\": 'YYYY-MM-DD',\n",
    "#         \"arrive_date\": 'YYYY-MM-DD',\n",
    "#         \"has_r2rnav\": true/false,\n",
    "#     },\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "\n",
    "cruisesDict = dict()\n",
    "\n",
    "# progressBar = tqdm(sorted(tempSetCruises), desc=\"Requesting Cruise metadata\", unit=\"request\")\n",
    "progressBar = tqdm(sorted(tempSetCruises), unit=\"request\")\n",
    "for cruiseID in progressBar:\n",
    "    # progressBar.set_description(\"Requesting {0} data. Total Progress:\".format(cruiseID))\n",
    "    # ok, why did I change from use description?? Test or leave it...\n",
    "    progressBar.set_postfix_str(\"Requesting {0} data.\".format(cruiseID))\n",
    "\n",
    "    # TODO: currently cruisesDict is only updated/added-to if R2R has metadata on the cruise... will R2R have a cruise personnel list but not metadata?\n",
    "    #  how to handle NautilusLive cruises that R2R doesn't have?\n",
    "    #  always create a dict entry with just... cruise_id and ... `error_notes` that is human readable?\n",
    "\n",
    "    # from https://pycoders-nl.gitbook.io/pycoders-handbook/web-scraping/week-14/python-requests-library-and-fastapi#how-to-make-robust-api-requests\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            \"https://service.rvdata.us/api/cruise/cruise_id/{0}\".format(cruiseID),\n",
    "            timeout=req_timeout,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            tempDict = {\n",
    "                \"cruise_id\": response.json()[\"data\"][0][\"cruise_id\"],\n",
    "                \"cruise_name\": response.json()[\"data\"][0][\"cruise_name\"],\n",
    "                \"depart_date\": response.json()[\"data\"][0][\"depart_date\"],\n",
    "                \"arrive_date\": response.json()[\"data\"][0][\"arrive_date\"],\n",
    "                \"has_r2rnav\": response.json()[\"data\"][0][\"has_r2rnav\"],\n",
    "            }\n",
    "\n",
    "            cruisesDict.update({tempDict[\"cruise_id\"]: tempDict})\n",
    "        elif response.status_code == 204:\n",
    "            print(\"ERROR: Cruise ID {0} returns 'No Cruise Found' from R2R\".format(cruiseID))\n",
    "        else:\n",
    "            print(\n",
    "                \"ERROR: Cruise ID {0} returns Code {1}, text {2}\".format(\n",
    "                    cruiseID,\n",
    "                    str(response.status_code),\n",
    "                    response.text[\"status_message\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Pause for `wait_time` seconds between each request to be nice. Longer?\n",
    "        time.sleep(wait_time)\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print(errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print(errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(err)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Manually add missing cruise IDs",
   "id": "d49c7b156bdd108d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: allow user to add cruise IDs that were not found in R2R.\n",
    "#  validate they are correct format if they start with `NA`.\n",
    "#  Then check if they exist in R2R, if not, add to cruisesDict with error note.\n",
    "#  Check if non-R2R-existent cruises have data in data-local, otherwise warn user that data will not be found for those cruises."
   ],
   "id": "37495e17b5689aa0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Get links to nav data files (and their data formats) for each cruise",
   "id": "4d198968e920511c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the urls for r2rnav files for all applicable cruises\n",
    "\n",
    "progressBar = tqdm(cruisesDict.keys())\n",
    "for cruiseID in progressBar:\n",
    "    progressBar.set_postfix_str(\"Requesting {0} url.\".format(cruiseID))\n",
    "    # print(\"Cruise {0} has r2rnav data? {1}\".format(cruiseID, cruisesDict[cruiseID]['has_r2rnav']))\n",
    "\n",
    "    if cruisesDict[cruiseID][\"has_r2rnav\"]:\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                \"https://service.rvdata.us/api/product/cruise_id/{0}\".format(cruiseID),\n",
    "                timeout=req_timeout,\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "\n",
    "            r2rnav_expected_format = \"r2rnav_geocsv\"\n",
    "            r2rnav_expected_format2 = \"r2rnav\"\n",
    "            r2rnav_expected_formats = [\"r2rnav_geocsv\", \"r2rnav\"]\n",
    "            r2rnav_product_found = False\n",
    "            r2rnav_found_formats = []\n",
    "            r2rnav_url_found = False\n",
    "            r2rnav_url_valid = False\n",
    "            data_product_formats = []\n",
    "\n",
    "            # Try each format in order of preference\n",
    "            for r2rnav_format in r2rnav_expected_formats:\n",
    "                if not r2rnav_url_found:  # will be false on the first instance of for loop, so on later loops: do not execute code if we already found the nav_url\n",
    "                    for dataProduct in response.json()[\"data\"]:\n",
    "                        # first check that this is a data product we care about right now (i.e. it is nav, not CTD data etc somehow)\n",
    "                        if dataProduct[\"file_format\"] == r2rnav_format:\n",
    "                            r2rnav_product_found = True\n",
    "                            r2rnav_found_formats.append(dataProduct[\"file_format\"])\n",
    "\n",
    "                            # Check if the keys for the `url` and `actual_url` are present and non-empty\n",
    "                            if \"url\" in dataProduct and dataProduct[\"url\"] and \"actual_url\" in dataProduct and \\\n",
    "                                    dataProduct[\"actual_url\"]:\n",
    "                                r2rnav_url_found = True\n",
    "                                cruisesDict[cruiseID].update({\n",
    "                                    \"r2rnav_url\": dataProduct[\"url\"],\n",
    "                                    \"r2rnav_url_actual\": dataProduct[\"actual_url\"],\n",
    "                                    \"r2rnav_format\": dataProduct[\"file_format\"],\n",
    "                                    \"has_r2rnav_valid_url\": False\n",
    "                                })\n",
    "\n",
    "                                # now let's try to access the `actual_url`\n",
    "                                try:\n",
    "                                    # Test if URL is accessible\n",
    "                                    url_check = requests.head(dataProduct[\"actual_url\"], timeout=req_timeout)\n",
    "                                    url_check.raise_for_status()\n",
    "\n",
    "                                    cruisesDict[cruiseID].update({\n",
    "                                        \"has_r2rnav_valid_url\": True\n",
    "                                    })\n",
    "                                    r2rnav_url_valid = True\n",
    "                                except requests.exceptions.RequestException:\n",
    "                                    pass\n",
    "                            # ok they weren't present and non-empty\n",
    "                            else:\n",
    "                                if \"url\" in dataProduct and \"actual_url\" in dataProduct:  # test if keys are present\n",
    "                                    # TODO: code out further non-empty url/actual_url tests if needed\n",
    "                                    if not dataProduct[\"actual_url\"]:  # test if actual_url is non-empty\n",
    "                                        print(\"ERROR: Cruise {0} has a data product with a null `actual_url`\".format(\n",
    "                                            cruiseID))\n",
    "\n",
    "                                        # update `has_r2rnav_valid_url` to false, since we only use `actual_url` to download data file\n",
    "                                        cruisesDict[cruiseID].update({\n",
    "                                            \"has_r2rnav_valid_url\": False,\n",
    "                                        })\n",
    "\n",
    "                                    if dataProduct[\"url\"]:  # test if url is non-empty\n",
    "                                        print(\"ERROR: Cruise {0} has a data product with a null `url`\".format(cruiseID))\n",
    "                                else:\n",
    "                                    # the keys weren't present...?\n",
    "                                    print(\n",
    "                                        \"ERROR: Cruise {0} has a data product with no `url` and `actual_url` keys\".format(\n",
    "                                            cruiseID))\n",
    "\n",
    "                                # print json result for debugging\n",
    "                                print(dataProduct)\n",
    "\n",
    "            if not r2rnav_url_valid:\n",
    "                if not r2rnav_url_found:\n",
    "                    if not r2rnav_product_found:\n",
    "                        print(\n",
    "                            \"ERROR: Failed to find {0} formatted data products for Cruise {1}, even though `has_r2rnav` is True\".format(\n",
    "                                \", OR \".join(r2rnav_expected_formats),\n",
    "                                cruiseID\n",
    "                            )\n",
    "                        )\n",
    "                        for dataProduct in response.json()[\"data\"]:\n",
    "                            # start making a list of encountered data format types in case we need to use it in error message below\n",
    "                            data_product_formats.append(dataProduct[\"file_format\"])\n",
    "                    else:  #yes product, no url\n",
    "                        print(\n",
    "                            \"ERROR: No 'actual_url' found for Cruise {0}, but `has_r2rnav` is True and found {1} formatted data product(s)\".format(\n",
    "                                cruiseID, \", \".join(r2rnav_found_formats)\n",
    "                            )\n",
    "                        )\n",
    "                else:  # `actual_url` exists and is non-empty, but we could not access it\n",
    "                    print(\n",
    "                        \"WARN: Failed to access 'actual_url' for Cruise {0}. This could be a temporary error... \"\n",
    "                    )\n",
    "\n",
    "            # Pause for `wait_time` seconds between each request to be nice. Longer?\n",
    "            time.sleep(wait_time)\n",
    "        except requests.exceptions.HTTPError as errh:\n",
    "            print(errh)\n",
    "        except requests.exceptions.ConnectionError as errc:\n",
    "            print(errc)\n",
    "        except requests.exceptions.Timeout as errt:\n",
    "            print(errt)\n",
    "        except requests.exceptions.RequestException as err:\n",
    "            print(err)\n",
    "\n",
    "    # else: # Do something to alert user to cruises without r2rnav? don't need to do here, just loop through dict again for if !has_r2rnav #NA096 and 3 other have this other format. txt from r2r saved in this code dir."
   ],
   "id": "11834e43e80cac50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test output so far\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(cruisesDict)"
   ],
   "id": "d3fe1494728f045a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test output so far, specifically which cruises don't have r2rnav files\n",
    "cruises_missing_r2rnav = []\n",
    "cruises_missing_url_r2rnav = []\n",
    "\n",
    "for cruiseID in cruisesDict:\n",
    "    if not cruisesDict[cruiseID][\"has_r2rnav\"]:\n",
    "        cruises_missing_r2rnav.append(cruiseID)\n",
    "    else:\n",
    "        if \"r2rnav_url_actual\" not in cruisesDict[cruiseID]:\n",
    "            cruises_missing_url_r2rnav.append(cruiseID)\n",
    "\n",
    "if cruises_missing_r2rnav:\n",
    "    print(\n",
    "        \"The following cruises don't have r2rnav data, will need to parse INS data or do something else:\\n {0}\".format(\n",
    "            \", \".join(cruises_missing_r2rnav)\n",
    "        )\n",
    "    )\n",
    "\n",
    "for cruiseID in cruisesDict:\n",
    "    #if not cruisesDict[cruiseID][\"has_r2rnav\"]:\n",
    "    if cruisesDict[cruiseID][\"has_r2rnav\"]:\n",
    "        if \"r2rnav_url_actual\" not in cruisesDict[cruiseID]:\n",
    "            cruises_missing_r2rnav.append(cruiseID)\n",
    "\n",
    "if cruises_missing_url_r2rnav:\n",
    "    print(\n",
    "        \"The following cruises don't have an 'actual url' to their r2rnav data, will need to parse INS data or do something else:\\n {0}\".format(\n",
    "            \", \".join(cruises_missing_url_r2rnav)\n",
    "        )\n",
    "    )"
   ],
   "id": "bc2122fb5ef3dcda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: download files\n",
    "\n",
    "# TODO: give option to load directly into memory?\n",
    "#  or download and save locally and load into memory\n",
    "#  (or is memory the smaller limit on mybinder and we should save all files to disk and load full data into memory only one at a time?)\n",
    "\n",
    "# TODO: what module to use to read in lat longs and get distance of path? can just pandas do this? or some specific geo module better? this will prob inform how we load the files into vars...\n",
    "# numpy?\n",
    "# https://github.com/pyproj4/pyproj ? maybe just coordinate transforms...\n",
    "# https://github.com/GenericMappingTools/pygmt\n",
    "# hmm apparently GeoPandas is a thing? https://geopandas.org/en/stable/getting_started/introduction.html and pretty maps in jupyter??\n",
    "\n",
    "# a bunch of words. https://www.geeksforgeeks.org/working-with-geospatial-data-in-python/\n"
   ],
   "id": "c3b261f057bf95a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: check for nav files, download as needed - do the below...\n",
    "# loop through list of URLs - first check if file already exists locally, if not, then download it\n",
    "#  add location of local file (previously existent or ust downloaded) to cruisesDict under new key 'r2rnav_local_file'\n",
    "\n"
   ],
   "id": "29124e7c5f421ae6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Notes\n",
    "\n",
    "useful for later - to check if url goes to a tar.gz file or a directory:\n",
    "\n",
    "```python\n",
    "regex = r\".*\\.tar\\.gz$\"\n",
    "if re.match(regex,response.json()['data'][0]['actual_url']):\n",
    "    print(\"tar.gz url\")\n",
    "```\n",
    "\n",
    "# starting point for r2rnav files\n",
    "\n",
    "NA041 returns: 'r2rnav_url_actual': 'https://www.ncei.noaa.gov/archive/accession/0296681/data/0-data/NA041_615289_r2rnav/'\n",
    "\n",
    "in that dir is:\n",
    "\n",
    "https://www.ncei.noaa.gov/data/oceans/archive/arc0228/0296681/1.3/data/0-data/NA041_615289_r2rnav/data/NA041_1min.r2rnav\n",
    "\n",
    "so something like `\"{0}/data/{1}_1min.r2rnav\".format(cruisesDict[cruiseID]['r2rnav_url_actual'], cruiseID)` and download it\n"
   ],
   "id": "e3aaba8d3d0226e8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
