{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284fb908a0bc5fc7",
   "metadata": {},
   "source": [
    "# Tell me about my seatime (Using information from R2R)\n",
    "\n",
    "The Rolling Deck to Repository (R2R) Program publishes a [beautiful API here](https://www.rvdata.us/about/technical-details/services/api).\n",
    "\n",
    "The intention is to use a person's name to get all cruises they were on, then days on the ship, then miles sailed on each cruise.\n",
    "\n",
    "## Process Flow\n",
    "\n",
    "Get the cruises a person was on:\n",
    "\n",
    "1. run a `/person/person_id/{person_id}` query for iterations of Last and First names.\n",
    "2. Get a person's list of cruises from NautilusLive.org\n",
    "\n",
    "To get days and miles sailed, get data from R2R then process retrieved data file and/or local data files. Loop through all applicable cruises and process files (in order of preference of formats):\n",
    "\n",
    "1. Get R2R format processed nav from a `/product/cruise_id/{cruise_id}` query (not all cruises have this data ready to download)\n",
    "2. get INS data from `/fileset/cruise_id/{cruise_id}` query? (TODO)\n",
    "3. get data from OET people and just put it in data-local directory\n",
    "\n",
    "aaaand then process that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf461c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the values of these two variables to the person to search for\n",
    "# the variables are lists in order to account for multiple names due to spelling/punctation variations/mistakes, changed first or last names, etc.\n",
    "# e.g. lastNames = [\"Obrien\", \"O'Brien\", \"O'brian\"] etc. - for instances where the metadata sent to r2r was entered incorrectly\n",
    "# Note: Capitalization does not matter at all for r2r, and the names are converted to lowercase for NautilusLive.org\n",
    "# DO NOT use this to search for multiple people at once, it will join their records.\n",
    "lastNames = [\"Lowe\"]\n",
    "firstNames = [\"Justin\"]\n",
    "\n",
    "# How many seconds should we wait between making requests to R2R api?\n",
    "wait_time = 0.5\n",
    "req_timeout = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4958328fa22562",
   "metadata": {},
   "source": [
    "## Get Cruises from R2R with Person's Name(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67470653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cruises from r2r\n",
    "# https://www.rvdata.us/about/technical-details/services/api\n",
    "# Use format `LastName, FirstName` as person_id\n",
    "\n",
    "tempSetCruises = set()\n",
    "\n",
    "# Try all combinations of first and last names\n",
    "for lastName in lastNames:\n",
    "    for firstName in firstNames:\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                \"https://service.rvdata.us/api/person/person_id/{0}%2C%20{1}\".format(\n",
    "                    lastName, firstName\n",
    "                ),\n",
    "                timeout=req_timeout,\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "\n",
    "            searchNameResults = response.json()[\"data\"]\n",
    "\n",
    "            for cruiseResult in searchNameResults:\n",
    "                tempSetCruises.add(cruiseResult[\"cruise_id\"])\n",
    "\n",
    "            print(\n",
    "                \"Found {0} cruises for {1} {2}: {3}\".format(\n",
    "                    len(tempSetCruises),\n",
    "                    firstName,\n",
    "                    lastName,\n",
    "                    \", \".join(sorted(tempSetCruises)),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if len(firstNames) > 1 or len(lastNames) > 1:\n",
    "                # Pause between requests to be nice\n",
    "                time.sleep(wait_time)\n",
    "\n",
    "        except requests.exceptions.HTTPError as errh:\n",
    "            print(f\"HTTP Error for {firstName} {lastName}: {errh}\")\n",
    "        except requests.exceptions.ConnectionError as errc:\n",
    "            print(f\"Connection Error for {firstName} {lastName}: {errc}\")\n",
    "        except requests.exceptions.Timeout as errt:\n",
    "            print(f\"Timeout Error for {firstName} {lastName}: {errt}\")\n",
    "        except requests.exceptions.RequestException as err:\n",
    "            print(f\"Error for {firstName} {lastName}: {err}\")\n",
    "\n",
    "if len(firstNames) > 1 or len(lastNames) > 1:\n",
    "    print(\n",
    "        \"\\nFinal sorted list of all cruises found: {0}\".format(\n",
    "            \", \".join(sorted(tempSetCruises))\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\n",
    "    \"NOTE: If you notice any missing cruises or cruises you weren't on, you can modify the 'lastNames' and 'firstNames' lists at the top of this notebook.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e4d6f85435e75",
   "metadata": {},
   "source": [
    "## Try to also get Cruises from Person's page on NautilusLive.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f09e6d5f416e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also get cruise IDs from links on the user's NautilusLive.org page (if applicable)\n",
    "nlSetCruises = set()\n",
    "\n",
    "# NautilusLive.org user page base URL\n",
    "nautilusLivePageURL = \"https://nautiluslive.org/people/\"\n",
    "\n",
    "nlCruises = dict()\n",
    "\n",
    "# Try all combinations of names\n",
    "for firstName in firstNames:\n",
    "    for lastName in lastNames:\n",
    "        # combine first name with last name with hyphens, all lowercase\n",
    "        nautilusLivePageName = \"-\".join([firstName, lastName]).lower()\n",
    "\n",
    "        try:\n",
    "            # use BeautifulSoup to parse the HTML page and extract the links from all <div> elements with class=\"cruises\"\n",
    "            response = requests.get(nautilusLivePageURL + nautilusLivePageName)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            # find all <div> elements with class=\"cruises\"\n",
    "            cruiseLinks = soup.find_all(\"div\", class_=\"cruises\")\n",
    "\n",
    "            # extract the href attribute from each <a> element in the <div> elements with class=\"cruises\"\n",
    "            for div in cruiseLinks:\n",
    "                a_tags = div.find_all(\"a\")\n",
    "                for a in a_tags:\n",
    "                    href = a.get(\"href\")\n",
    "                    if href:\n",
    "                        # parse out the cruise ID from the href attribute e.g. \"NA160\" from \"/cruise/NA160\"\n",
    "                        cruise_id = href.split(\"/\")[-1]\n",
    "                        # Validate it is a valid cruise ID of the format \"NA\" and then three numbers\n",
    "                        if cruise_id.startswith(\"NA\") and len(cruise_id) == 5:\n",
    "                            nlSetCruises.add(cruise_id)\n",
    "\n",
    "                            # get name of link from <a> element\n",
    "                            cruise_name = a.get_text()\n",
    "                            # add cruise_id and cruise_name to nlCruises dict\n",
    "                            nlCruises[cruise_id] = cruise_name\n",
    "\n",
    "            if len(firstNames) > 1 or len(lastNames) > 1:\n",
    "                print(\n",
    "                    \"Found the following cruises on NautilusLive.org for {0} {1}\".format(\n",
    "                        firstName, lastName\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            time.sleep(wait_time)  # Be nice to the server\n",
    "\n",
    "        except requests.exceptions.RequestException as err:\n",
    "            print(f\"Error accessing NautilusLive.org for {firstName} {lastName}: {err}\")\n",
    "\n",
    "print(\n",
    "    \"\\nFinal sorted list of cruises from NautilusLive.org has {0} cruises: {1}. \\n\".format(\n",
    "        len(nlSetCruises), \", \".join(sorted(nlSetCruises))\n",
    "    )\n",
    ")\n",
    "\n",
    "# print out any cruises that are missing from either list\n",
    "if nlCruises and nlSetCruises != tempSetCruises:\n",
    "    missing_from_nl = sorted(tempSetCruises.difference(nlSetCruises))\n",
    "    if missing_from_nl:\n",
    "        if len(missing_from_nl) > 1:\n",
    "            print(\n",
    "                \"These {0} R2R cruises are missing from the person's NautilusLive list: {1}\".format(\n",
    "                    len(missing_from_nl), \", \".join(missing_from_nl)\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"This {0} R2R cruise is missing from the person's NautilusLive list: {1}\".format(\n",
    "                    len(missing_from_nl), missing_from_nl[0]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    missing_from_r2r = sorted(nlSetCruises.difference(tempSetCruises))\n",
    "    if missing_from_r2r:\n",
    "        if len(missing_from_r2r) > 1:\n",
    "            print(\n",
    "                \"These {0} NautilusLive cruises are missing from the person's R2R list: {1}\".format(\n",
    "                    len(missing_from_r2r),\n",
    "                    \", \".join(missing_from_r2r),\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"This {0} NautilusLive cruise is missing from the person's R2R list: {1}\".format(\n",
    "                    len(missing_from_r2r),\n",
    "                    missing_from_r2r[0],\n",
    "                )\n",
    "            )\n",
    "\n",
    "# TODO: use a new variable instead of just adding to existing set?\n",
    "print(\"Cruise list had {0} cruises from R2R\".format(len(tempSetCruises)))\n",
    "tempSetCruises = tempSetCruises.union(nlSetCruises)\n",
    "print(\n",
    "    \"Cruise list now has {0} cruises from R2R and NautilusLive\".format(\n",
    "        len(tempSetCruises)\n",
    "    )\n",
    ")\n",
    "# print(\", \".join(sorted(tempSetCruises)))\n",
    "\n",
    "# TODO: ask user if they want to union both sets of cruises? or just keep as is and add them without asking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1149a2c849236384",
   "metadata": {},
   "source": [
    "## Get metadata about each Cruise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7af198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through Cruises and get data. Use: dates, `has_r2rnav`, ?\n",
    "\n",
    "# exampleDict =\t{\n",
    "#     cruiseID: {\n",
    "#         \"cruise_id\": TEXT,\n",
    "#         \"cruise_name\": TEXT,\n",
    "#         \"depart_date\": 'YYYY-MM-DD',\n",
    "#         \"arrive_date\": 'YYYY-MM-DD',\n",
    "#         \"has_r2rnav\": true/false,\n",
    "#     },\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "\n",
    "cruisesDict = dict()\n",
    "\n",
    "# progressBar = tqdm(sorted(tempSetCruises), desc=\"Requesting Cruise metadata\", unit=\"request\")\n",
    "progressBar = tqdm(sorted(tempSetCruises), unit=\"request\")\n",
    "for cruiseID in progressBar:\n",
    "    # progressBar.set_description(\"Requesting {0} data. Total Progress:\".format(cruiseID))\n",
    "    # ok, why did I change from use description?? Test or leave it...\n",
    "    progressBar.set_postfix_str(\"Requesting {0} data.\".format(cruiseID))\n",
    "\n",
    "    # TODO: currently cruisesDict is only updated/added-to if R2R has metadata on the cruise... will R2R have a cruise personnel list but not metadata?\n",
    "    #  how to handle NautilusLive cruises that R2R doesn't have?\n",
    "    #  always create a dict entry with just... cruise_id and ... `error_notes` that is human readable?\n",
    "\n",
    "    # from https://pycoders-nl.gitbook.io/pycoders-handbook/web-scraping/week-14/python-requests-library-and-fastapi#how-to-make-robust-api-requests\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            \"https://service.rvdata.us/api/cruise/cruise_id/{0}\".format(cruiseID),\n",
    "            timeout=req_timeout,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # TODO: add url for cruise's R2R page\n",
    "        if response.status_code == 200:\n",
    "            tempDict = {\n",
    "                \"cruise_id\": response.json()[\"data\"][0][\"cruise_id\"],\n",
    "                \"cruise_name\": response.json()[\"data\"][0][\"cruise_name\"],\n",
    "                \"depart_date\": response.json()[\"data\"][0][\"depart_date\"],\n",
    "                \"arrive_date\": response.json()[\"data\"][0][\"arrive_date\"],\n",
    "                \"has_r2rnav\": response.json()[\"data\"][0][\"has_r2rnav\"],\n",
    "            }\n",
    "\n",
    "            cruisesDict.update({tempDict[\"cruise_id\"]: tempDict})\n",
    "        elif response.status_code == 204:\n",
    "            print(\n",
    "                \"ERROR: Cruise ID {0} returns 'No Cruise Found' from R2R\".format(\n",
    "                    cruiseID\n",
    "                )\n",
    "            )\n",
    "            cruisesDict.update(\n",
    "                {\n",
    "                    cruiseID: {\n",
    "                        \"cruise_id\": cruiseID,\n",
    "                        \"cruise_name\": \"Unknown (Not in R2R)\",\n",
    "                        \"depart_date\": \"Unknown\",\n",
    "                        \"arrive_date\": \"Unknown\",\n",
    "                        \"has_r2rnav\": False,\n",
    "                        \"error_notes\": \"Not found in R2R\",\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"ERROR: Cruise ID {0} returns Code {1}, text {2}\".format(\n",
    "                    cruiseID,\n",
    "                    str(response.status_code),\n",
    "                    response.text,\n",
    "                )\n",
    "            )\n",
    "            cruisesDict.update(\n",
    "                {\n",
    "                    cruiseID: {\n",
    "                        \"cruise_id\": cruiseID,\n",
    "                        \"cruise_name\": \"Unknown (Error)\",\n",
    "                        \"depart_date\": \"Unknown\",\n",
    "                        \"arrive_date\": \"Unknown\",\n",
    "                        \"has_r2rnav\": False,\n",
    "                        \"error_notes\": f\"Error {response.status_code}\",\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Pause for `wait_time` seconds between each request to be nice. Longer?\n",
    "        time.sleep(wait_time)\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print(errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print(errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(err)\n",
    "        # cruisesDict.update({cruiseID: {\n",
    "        #     \"cruise_id\": cruiseID,\n",
    "        #     \"cruise_name\": \"Unknown (Request Error)\",\n",
    "        #     \"depart_date\": \"Unknown\",\n",
    "        #     \"arrive_date\": \"Unknown\",\n",
    "        #     \"has_r2rnav\": False,\n",
    "        #     \"error_notes\": str(err)\n",
    "        # }})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b98817f0934b754",
   "metadata": {},
   "source": [
    "## Manually add missing cruise IDs\n",
    "\n",
    "Type in missing cruise IDs below, e.g. `[\"NA123\", \"NA456\"]`\n",
    "Right now this notebook/script only parses r2rnav data,\n",
    "so ask your friendly DE for the generated r2rnav 1 min file,\n",
    "and then save/upload it to the `data-local` directory with the filename format `{cruiseID}_1min.r2rnav`,\n",
    "e.g. `NA123_1min.r2rnav`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4d04881fa13f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add missing cruise IDs\n",
    "manual_cruises = []  # Add cruise IDs here, e.g. [\"NA123\", \"NA456\"]\n",
    "\n",
    "for cruiseID in manual_cruises:\n",
    "    if cruiseID not in cruisesDict:\n",
    "        # Basic validation: starts with NA and has 3 digits (total length 5)\n",
    "        if cruiseID.startswith(\"NA\") and len(cruiseID) == 5:\n",
    "            cruisesDict.update(\n",
    "                {\n",
    "                    cruiseID: {\n",
    "                        \"cruise_id\": cruiseID,\n",
    "                        \"cruise_name\": \"Manual Entry\",\n",
    "                        \"depart_date\": \"Unknown\",\n",
    "                        \"arrive_date\": \"Unknown\",\n",
    "                        \"has_r2rnav\": False,\n",
    "                        \"error_notes\": \"Manually added\",\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "            print(f\"Added manual cruise {cruiseID}\")\n",
    "        else:\n",
    "            print(f\"Invalid manual cruise ID format: {cruiseID}\")\n",
    "    else:\n",
    "        print(f\"Cruise {cruiseID} already exists in list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d198968e920511c",
   "metadata": {},
   "source": [
    "## Get links to nav data files (and their data formats) for each cruise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11834e43e80cac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the urls for r2rnav files for all applicable cruises\n",
    "\n",
    "progressBar = tqdm(cruisesDict.keys())\n",
    "for cruiseID in progressBar:\n",
    "    progressBar.set_postfix_str(\"Requesting {0} url.\".format(cruiseID))\n",
    "    # print(\"Cruise {0} has r2rnav data? {1}\".format(cruiseID, cruisesDict[cruiseID]['has_r2rnav']))\n",
    "\n",
    "    if cruisesDict[cruiseID][\"has_r2rnav\"]:\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                \"https://service.rvdata.us/api/product/cruise_id/{0}\".format(cruiseID),\n",
    "                timeout=req_timeout,\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "\n",
    "            r2rnav_expected_format = \"r2rnav_geocsv\"\n",
    "            r2rnav_expected_format2 = \"r2rnav\"\n",
    "            r2rnav_expected_formats = [\"r2rnav_geocsv\", \"r2rnav\"]\n",
    "            r2rnav_product_found = False\n",
    "            r2rnav_found_formats = []\n",
    "            r2rnav_url_found = False\n",
    "            r2rnav_url_valid = False\n",
    "            data_product_formats = []\n",
    "\n",
    "            # Try each format in order of preference\n",
    "            for r2rnav_format in r2rnav_expected_formats:\n",
    "                if (\n",
    "                    not r2rnav_url_found\n",
    "                ):  # will be false on the first instance of for loop, so on later loops: do not execute code if we already found the nav_url\n",
    "                    for dataProduct in response.json()[\"data\"]:\n",
    "                        # first check that this is a data product we care about right now (i.e. it is nav, not CTD data etc somehow)\n",
    "                        if dataProduct[\"file_format\"] == r2rnav_format:\n",
    "                            r2rnav_product_found = True\n",
    "                            r2rnav_found_formats.append(dataProduct[\"file_format\"])\n",
    "\n",
    "                            # Check if the keys for the `url` and `actual_url` are present and non-empty\n",
    "                            if (\n",
    "                                \"url\" in dataProduct\n",
    "                                and dataProduct[\"url\"]\n",
    "                                and \"actual_url\" in dataProduct\n",
    "                                and dataProduct[\"actual_url\"]\n",
    "                            ):\n",
    "                                r2rnav_url_found = True\n",
    "                                cruisesDict[cruiseID].update(\n",
    "                                    {\n",
    "                                        \"r2rnav_url\": dataProduct[\"url\"],\n",
    "                                        \"r2rnav_url_actual\": dataProduct[\"actual_url\"],\n",
    "                                        \"r2rnav_format\": dataProduct[\"file_format\"],\n",
    "                                        \"has_r2rnav_valid_url\": False,\n",
    "                                    }\n",
    "                                )\n",
    "\n",
    "                                # now let's try to access the `actual_url`\n",
    "                                try:\n",
    "                                    # Test if URL is accessible\n",
    "                                    url_check = requests.head(\n",
    "                                        dataProduct[\"actual_url\"], timeout=req_timeout\n",
    "                                    )\n",
    "                                    url_check.raise_for_status()\n",
    "\n",
    "                                    cruisesDict[cruiseID].update(\n",
    "                                        {\"has_r2rnav_valid_url\": True}\n",
    "                                    )\n",
    "                                    r2rnav_url_valid = True\n",
    "                                except requests.exceptions.RequestException:\n",
    "                                    pass\n",
    "                            # ok they weren't present and non-empty\n",
    "                            else:\n",
    "                                if (\n",
    "                                    \"url\" in dataProduct and \"actual_url\" in dataProduct\n",
    "                                ):  # test if keys are present\n",
    "                                    # TODO: code out further non-empty url/actual_url tests if needed\n",
    "                                    if not dataProduct[\n",
    "                                        \"actual_url\"\n",
    "                                    ]:  # test if actual_url is non-empty\n",
    "                                        print(\n",
    "                                            \"ERROR: Cruise {0} has a data product with a null `actual_url`\".format(\n",
    "                                                cruiseID\n",
    "                                            )\n",
    "                                        )\n",
    "\n",
    "                                        # update `has_r2rnav_valid_url` to false, since we only use `actual_url` to download data file\n",
    "                                        cruisesDict[cruiseID].update(\n",
    "                                            {\n",
    "                                                \"has_r2rnav_valid_url\": False,\n",
    "                                            }\n",
    "                                        )\n",
    "\n",
    "                                    if dataProduct[\"url\"]:  # test if url is non-empty\n",
    "                                        print(\n",
    "                                            \"ERROR: Cruise {0} has a data product with a null `url`\".format(\n",
    "                                                cruiseID\n",
    "                                            )\n",
    "                                        )\n",
    "                                else:\n",
    "                                    # the keys weren't present...?\n",
    "                                    print(\n",
    "                                        \"ERROR: Cruise {0} has a data product with no `url` and `actual_url` keys\".format(\n",
    "                                            cruiseID\n",
    "                                        )\n",
    "                                    )\n",
    "\n",
    "                                # print json result for debugging\n",
    "                                print(dataProduct)\n",
    "\n",
    "            if not r2rnav_url_valid:\n",
    "                if not r2rnav_url_found:\n",
    "                    if not r2rnav_product_found:\n",
    "                        print(\n",
    "                            \"ERROR: Failed to find {0} formatted data products for Cruise {1}, even though `has_r2rnav` is True\".format(\n",
    "                                \", OR \".join(r2rnav_expected_formats), cruiseID\n",
    "                            )\n",
    "                        )\n",
    "                        for dataProduct in response.json()[\"data\"]:\n",
    "                            # start making a list of encountered data format types in case we need to use it in error message below\n",
    "                            data_product_formats.append(dataProduct[\"file_format\"])\n",
    "                    else:  # yes product, no url\n",
    "                        print(\n",
    "                            \"ERROR: No 'actual_url' found for Cruise {0}, but `has_r2rnav` is True and found {1} formatted data product(s)\".format(\n",
    "                                cruiseID, \", \".join(r2rnav_found_formats)\n",
    "                            )\n",
    "                        )\n",
    "                else:  # `actual_url` exists and is non-empty, but we could not access it\n",
    "                    print(\n",
    "                        \"WARN: Failed to access 'actual_url' for Cruise {0}. This could be a temporary error... \"\n",
    "                    )\n",
    "\n",
    "            # Pause for `wait_time` seconds between each request to be nice. Longer?\n",
    "            time.sleep(wait_time)\n",
    "        except requests.exceptions.HTTPError as errh:\n",
    "            print(errh)\n",
    "        except requests.exceptions.ConnectionError as errc:\n",
    "            print(errc)\n",
    "        except requests.exceptions.Timeout as errt:\n",
    "            print(errt)\n",
    "        except requests.exceptions.RequestException as err:\n",
    "            print(err)\n",
    "\n",
    "    # else: # Do something to alert user to cruises without r2rnav? don't need to do here, just loop through dict again for if !has_r2rnav #NA096 and 3 other have this other format. txt from r2r saved in this code dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b261f057bf95a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what module to use to read in lat longs and get distance of path? can just pandas do this? or some specific geo module better? this will prob inform how we load the files into vars...\n",
    "# numpy?\n",
    "# https://github.com/pyproj4/pyproj ? maybe just coordinate transforms...\n",
    "# https://github.com/GenericMappingTools/pygmt\n",
    "# hmm apparently GeoPandas is a thing? https://geopandas.org/en/stable/getting_started/introduction.html and pretty maps in jupyter??\n",
    "\n",
    "# a bunch of words. https://www.geeksforgeeks.org/working-with-geospatial-data-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c575b10fd20f4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from other notebook\n",
    "# can use magic run command\n",
    "%run process_r2rnav.ipynb\n",
    "\n",
    "# # or use special module to import notebooks\n",
    "# import import_ipynb\n",
    "# # from process_r2rnav import calculate_track_length\n",
    "# import process_r2rnav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82102f1cc938529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required data for cruises\n",
    "import tarfile\n",
    "\n",
    "pbar = tqdm(cruisesDict.keys())\n",
    "for cruiseID in pbar:\n",
    "    pbar.set_description(f\"Checking {cruiseID}\")\n",
    "\n",
    "    # Check for local files first\n",
    "    local_r2r_file = os.path.join(\"data-local\", f\"{cruiseID}_1min.r2rnav\")\n",
    "    local_csv_file = os.path.join(\"data-local\", f\"{cruiseID}.csv\")\n",
    "\n",
    "    # check that there is a valid URL for this cruise's r2rnav data AND that we don't have it locally yet, then download it\n",
    "    if cruisesDict[cruiseID].get(\"has_r2rnav_valid_url\", False) and not os.path.exists(\n",
    "        local_r2r_file\n",
    "    ):\n",
    "        pbar.set_description(f\"Downloading {cruiseID}\")\n",
    "        url = cruisesDict[cruiseID][\"r2rnav_url_actual\"]\n",
    "\n",
    "        # If URL points to a directory, construct the expected file URL\n",
    "        if not url.endswith(\".tar.gz\") and not url.endswith(\".r2rnav\"):\n",
    "            url = f\"{url.rstrip('/')}/data/{cruiseID}_1min.r2rnav\"\n",
    "\n",
    "        try:\n",
    "            filename = download_file(url, \"data-local\")\n",
    "\n",
    "            if filename.endswith(\".tar.gz\"):\n",
    "                pbar.set_description(f\"Extracting {cruiseID}\")\n",
    "                try:\n",
    "                    with tarfile.open(filename, \"r:gz\") as tar:\n",
    "                        tar.extractall(path=\"data-local\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting {filename}: {e}\")\n",
    "\n",
    "                # Search for the expected file if it was in a subdirectory\n",
    "                if not os.path.exists(local_r2r_file):\n",
    "                    for root, dirs, files in os.walk(\"data-local\"):\n",
    "                        if f\"{cruiseID}_1min.r2rnav\" in files:\n",
    "                            found_path = os.path.join(root, f\"{cruiseID}_1min.r2rnav\")\n",
    "                            os.rename(found_path, local_r2r_file)\n",
    "                            break\n",
    "\n",
    "            if os.path.exists(local_r2r_file):\n",
    "                cruisesDict[cruiseID][\"r2rnav_local_file\"] = local_r2r_file\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading/processing r2rnav data file for {cruiseID}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756c5bc216f61c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all cruises, using local files (which already existed or were downloaded in above cell)\n",
    "# print(\"Processing Cruises...\")\n",
    "pbar = tqdm(cruisesDict.keys())\n",
    "for cruiseID in pbar:\n",
    "    pbar.set_description(f\"Processing {cruiseID}\")\n",
    "\n",
    "    # Check for local files first\n",
    "    local_r2r_file = os.path.join(\"data-local\", f\"{cruiseID}_1min.r2rnav\")\n",
    "    local_csv_file = os.path.join(\"data-local\", f\"{cruiseID}.csv\")\n",
    "\n",
    "    stats = None\n",
    "    num_points = 0\n",
    "\n",
    "    if os.path.exists(local_r2r_file):\n",
    "        pbar.set_description(f\"Processing {cruiseID} (R2R)\")\n",
    "        stats, num_points = process_single_r2rnav_file(local_r2r_file)\n",
    "    elif os.path.exists(local_csv_file):\n",
    "        pbar.set_description(f\"Processing {cruiseID} (CSV)\")\n",
    "        # Stub for CSV processing\n",
    "        df = read_simple_csv_nav(local_csv_file)\n",
    "        if not df.empty:\n",
    "            stats = calculate_track_length(df)\n",
    "            num_points = len(df)\n",
    "\n",
    "            start_time = df[\"datetime\"].min()\n",
    "            end_time = df[\"datetime\"].max()\n",
    "            elapsed_hours = (end_time - start_time).total_seconds() / 3600\n",
    "            stats[\"elapsed_hours\"] = round(elapsed_hours, 1)\n",
    "            stats[\"start_time\"] = start_time\n",
    "            stats[\"end_time\"] = end_time\n",
    "\n",
    "    if stats:\n",
    "        cruisesDict[cruiseID].update({\"track_stats\": stats, \"num_points\": num_points})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e06c552a1bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display total statistics\n",
    "total_stats = {\n",
    "    \"kilometers\": 0,\n",
    "    \"miles\": 0,\n",
    "    \"nautical_miles\": 0,\n",
    "    \"total_points\": 0,\n",
    "    \"total_days\": 0,\n",
    "}\n",
    "\n",
    "cruises_missing_r2rnav = []\n",
    "print(\"\\nResults by cruise:\")\n",
    "print(\"ID\\tDepart\\t\\tArrive\\t\\tDays\\tPoints\\tKm\\tMi\\tNMi\")\n",
    "for cruiseID, cruise_data in sorted(cruisesDict.items()):\n",
    "    # TODO: also breakout days on ship by year\n",
    "    # Set days_elapsed to zero in case there is no valid date info\n",
    "    days_elapsed = 0\n",
    "    if (\n",
    "        cruise_data.get(\"depart_date\")\n",
    "        and cruise_data.get(\"arrive_date\")\n",
    "        and cruise_data[\"depart_date\"] != \"Unknown\"\n",
    "        and cruise_data[\"arrive_date\"] != \"Unknown\"\n",
    "    ):\n",
    "        # Calculate days elapsed from metadata dates\n",
    "        try:\n",
    "            start_date = datetime.strptime(cruise_data[\"depart_date\"], \"%Y-%m-%d\")\n",
    "            end_date = datetime.strptime(cruise_data[\"arrive_date\"], \"%Y-%m-%d\")\n",
    "            # Inclusive calculation: (end - start) + 1 day\n",
    "            days_elapsed = (end_date - start_date).days + 1\n",
    "            # print(f\"Days Elapsed: {days_elapsed}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Days Elapsed: Error calculating ({e})\")\n",
    "    else:\n",
    "        print(\"Days Elapsed: Unknown\")\n",
    "\n",
    "    # Store days elapsed\n",
    "    cruise_data[\"days_elapsed\"] = days_elapsed\n",
    "\n",
    "    # Update totals\n",
    "    total_stats[\"total_days\"] += days_elapsed\n",
    "\n",
    "    if \"track_stats\" in cruise_data:\n",
    "        for key in total_stats:\n",
    "            if key == \"total_points\":\n",
    "                total_stats[key] += cruise_data[\"num_points\"]\n",
    "            elif key in cruise_data[\"track_stats\"]:\n",
    "                total_stats[key] += cruise_data[\"track_stats\"][key]\n",
    "\n",
    "        print(\n",
    "            \"{}\\t\"\n",
    "            \"{}\\t\"\n",
    "            \"{}\\t\"\n",
    "            \"{}\\t\"\n",
    "            \"{}\\t\"\n",
    "            \"{:.1f}\\t\"\n",
    "            \"{:.1f}\\t\"\n",
    "            \"{:.1f}\\t\".format(\n",
    "                cruiseID,\n",
    "                cruise_data[\"depart_date\"],\n",
    "                cruise_data[\"arrive_date\"],\n",
    "                days_elapsed,\n",
    "                cruise_data[\"num_points\"],\n",
    "                cruise_data[\"track_stats\"][\"kilometers\"],\n",
    "                cruise_data[\"track_stats\"][\"miles\"],\n",
    "                cruise_data[\"track_stats\"][\"nautical_miles\"],\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        cruises_missing_r2rnav.append(cruiseID)\n",
    "        print(\n",
    "            \"{}\\t\"\n",
    "            \"{}\\t\"\n",
    "            \"{}\\t\"\n",
    "            \"{}\\t\"\n",
    "            \"N/A\\t\"\n",
    "            \"N/A\\t\"\n",
    "            \"N/A\\t\"\n",
    "            \"N/A\\t\".format(\n",
    "                cruiseID,\n",
    "                cruise_data[\"depart_date\"],\n",
    "                cruise_data[\"arrive_date\"],\n",
    "                days_elapsed,\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(\"\\nTotal Statistics:\")\n",
    "print(f\"Total Cruises:     {len(cruisesDict)}\")\n",
    "print(f\"Total Days:     {total_stats['total_days']}\")\n",
    "print(f\"Total Distance: {total_stats['kilometers']:.1f} km\")\n",
    "print(f\"              {total_stats['miles']:.1f} mi\")\n",
    "print(f\"              {total_stats['nautical_miles']:.1f} nm\")\n",
    "print(f\"Total Points: {total_stats['total_points']}\")\n",
    "if cruises_missing_r2rnav:\n",
    "    print(f\"\")\n",
    "    print(\n",
    "        f\"{len(cruises_missing_r2rnav)} cruise(s) missing r2rnav data: {', '.join(cruises_missing_r2rnav)}\"\n",
    "    )\n",
    "\n",
    "# Save results to files - json and csv\n",
    "today_str = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "lname = lastNames[0] if \"lastNames\" in locals() and lastNames else \"Unknown\"\n",
    "fname = firstNames[0] if \"firstNames\" in locals() and firstNames else \"Unknown\"\n",
    "base_filename = f\"seatime-{lname}-{fname}-{today_str}\"\n",
    "\n",
    "# JSON\n",
    "json_filename = f\"{base_filename}.json\"\n",
    "with open(json_filename, \"w\") as f:\n",
    "    json.dump(cruisesDict, f, indent=2, default=str)\n",
    "print(f\"\\nSaved JSON to {json_filename}\")\n",
    "\n",
    "# CSV\n",
    "csv_filename = f\"{base_filename}.csv\"\n",
    "csv_data = []\n",
    "for cruise_id, data in sorted(cruisesDict.items()):\n",
    "    row = data.copy()\n",
    "    # Flatten track_stats if present\n",
    "    if \"track_stats\" in row:\n",
    "        stats = row.pop(\"track_stats\")\n",
    "        for k, v in stats.items():\n",
    "            row[f\"stats_{k}\"] = v\n",
    "    csv_data.append(row)\n",
    "\n",
    "if csv_data:\n",
    "    df_csv = pd.DataFrame(csv_data)\n",
    "    # Reorder columns to put important ones first\n",
    "    cols = [\n",
    "        \"cruise_id\",\n",
    "        \"cruise_name\",\n",
    "        \"depart_date\",\n",
    "        \"arrive_date\",\n",
    "        \"days_elapsed\",\n",
    "        \"stats_kilometers\",\n",
    "        \"stats_nautical_miles\",\n",
    "    ]\n",
    "    # Add remaining columns\n",
    "    cols += [c for c in df_csv.columns if c not in cols]\n",
    "    # Filter cols that actually exist\n",
    "    cols = [c for c in cols if c in df_csv.columns]\n",
    "    df_csv = df_csv[cols]\n",
    "\n",
    "    df_csv.to_csv(csv_filename, index=False)\n",
    "    print(f\"Saved CSV to {csv_filename}\")\n",
    "else:\n",
    "    print(\"No data to save to CSV\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
